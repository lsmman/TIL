{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 앙상블\n",
    "\n",
    "Ref. https://swalloow.github.io/bagging-boosting\n",
    "\n",
    "- ### 앙상블이란\n",
    "    - 약한 학습기 (weak trainer)를 조합하여 성능이 높은 분류기를 만드는 방법\n",
    "    - 약한 학습기의 종류에 따라 2개로 분류 할 수 있다. (Bagging, Boosting)\n",
    "    \n",
    "    \n",
    "- ### Bagging\n",
    "    - 샘플을 여러 번 각 모델에 학습시켜 결과를 집계(Aggregating)하는 방식\n",
    "    - 약한 학습기 각각을 복원 랜덤 샘플링한 데이터로 학습시킴 <br/> -> 모델의 예측변수들을 집계 <br/>-> 그 결과로 모델을 생성\n",
    "    \n",
    "    \n",
    "- Bagging의 장점    \n",
    "    - 대부분 학습에서 나타나는 오류는 다음 두 가지다.\n",
    "        - 높은 bias로 인한 underfitting\n",
    "        - 높은 Variance로 인한 overfitting\n",
    "    \n",
    "    - Bagging은 overfitting을 방지하기 효과적이다.\n",
    "        - 각 샘플의 결과를 집계하므로 중간 값을 사용한다고 볼 수 있음\n",
    "        \n",
    "    - Bagging은 데이터를 일반화하여 분류하는 모델에 적합\n",
    "    \n",
    "    \n",
    "- Bagging의 집계 방식\n",
    "    - 집계 방식\n",
    "        - Categorical data면 voting으로 집계\n",
    "        - Continuous data면 Average로 집계\n",
    "    - RandomForest 모델이 대표적\n",
    "        - 단일 Decision Tree모델은 discrete(1차)한 모양이지만,\n",
    "        - 여러 트리 모델을 결합하여 높은 차원의 모델(n차)로 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
